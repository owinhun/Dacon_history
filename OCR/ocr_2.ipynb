{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# deep-text-recognition-benchmark의 dependency 설치\n",
    "# !pip install lmdb pillow torchvision nltk natsort fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2-1. [한국어 글자체 이미지](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osh/.conda/envs/osh/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import natsort\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('/home/osh/Text Recognition/train.csv')[['img_path', 'label']]\n",
    "# for i, e in enumerate(train['img_path']):\n",
    "#     e = \"/home/osh/Text Recognition\" + e[1:]\n",
    "#     train['img_path'][i] = e\n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train.to_csv(\"train2.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('train2.csv')\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('test2.csv')\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('/home/osh/Text Recognition/test.csv')[['img_path']]\n",
    "# for i, e in enumerate(test['img_path']):\n",
    "#     e = \"/home/osh/Text Recognition\" + e[1:]\n",
    "#     test['img_path'][i] = e\n",
    "# test.to_csv('test2.csv', index = False)\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Dacon 데이터 전처리 및 lmdb 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3-1. train.csv 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨링이 잘못되어있거나 누락된 데이터 수정 -> train_edit.csv 로 저장\n",
    "# train_csv_path = '/home/osh/Ocr/customocr-master/customocr-master/train2.csv'\n",
    "# train_csv = pd.read_csv(train_csv_path)\n",
    "# test_csv_path = '/home/osh/Ocr/customocr-master/customocr-master/test2.csv'\n",
    "# test_csv = pd.read_csv(test_csv_path)\n",
    "\n",
    "# # lmdb 데이터 생성을 위한 gt 파일 생성\n",
    "# train_csv[:-1000].to_csv('./lmdb_gt/train.txt', sep='\\t', header=False, index=False)\n",
    "\n",
    "# # 최종 학습 단계의 모델 저장을 위한 임시 validation gt 파일 생성\n",
    "# train_csv[-1000:].to_csv('./lmdb_gt/valid.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3-2. 학습에 사용할 lmdb 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# window 환경에서 작업 시의 lmdb 파일 생성 명령어:\n",
    "# !python ./hallymocr/create_lmdb_dataset.py --inputPath [데이터 root 경로] --gtFile [txt 파일 경로] --outputPath [데이터 저장 경로] --file_size [데이터 총 크기(GB)]\n",
    "\n",
    "# linux 환경에서 작업 시의 lmdb 파일 생성 명령어:\n",
    "# !python3 ./hallymocr/create_lmdb_dataset.py --inputPath [데이터 root 경로] --gtFile [txt 파일 경로] --outputPath [데이터 저장 경로] --file_size [데이터 총 크기(GB)]\n",
    "# '''\n",
    "# # !python ./hallymocr/create_lmdb_dataset.py --inputPath ./images/crop_valid --gtFile ./lmdb_data/hub_vlabel.txt --outputPath ./result/hvalid --file_size 5\n",
    "\n",
    "# # print('한국어 글자체 (tiw) lmdb 생성')\n",
    "# # !python ./hallymocr/create_lmdb_dataset.py --inputPath '' --gtFile ./lmdb_gt/crop_data.txt --outputPath ./result/tiw --file_size 10\n",
    "\n",
    "# # print('야외 실제 촬영 데이터 lmdb 생성')\n",
    "# # !python ./hallymocr/create_lmdb_dataset.py --inputPath '' --gtFile ./lmdb_gt/hub_tlabel.txt --outputPath ./result/htrain --file_size 20\n",
    "\n",
    "# print('Dacon 제공 데이터셋 ( : -1000 만큼 train 할당')\n",
    "# !python /home/osh/Ocr/customocr-master/customocr-master/hallymocr/create_lmdb_dataset.py --inputPath '' --gtFile /home/osh/Ocr/customocr-master/customocr-master/lmdb_gt/train.txt --outputPath /home/osh/Ocr/customocr-master/customocr-master/result/train --file_size 5\n",
    "\n",
    "# print('Dacon 제공 데이터셋 ( -1000 :  만큼 valid 할당')\n",
    "# !python /home/osh/Ocr/customocr-master/customocr-master/hallymocr/create_lmdb_dataset.py --inputPath '' --gtFile /home/osh/Ocr/customocr-master/customocr-master/lmdb_gt/valid.txt --outputPath /home/osh/Ocr/customocr-master/customocr-master/result/valid --file_size 2\n",
    "\n",
    "# print('Dacon 제공 데이터셋 ( -1000 :  만큼 test 할당')\n",
    "# !python /home/osh/Ocr/customocr-master/customocr-master/hallymocr/create_lmdb_dataset.py --inputPath '' --gtFile /home/osh/Ocr/customocr-master/customocr-master/lmdb_gt/test.txt --outputPath /home/osh/Ocr/customocr-master/customocr-master/result/test --file_size 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OCR 모델 학습\n",
    "1차 학습은 외부데이터로만 학습을 진행(crop약 160만장)하며, validation set은 Dacon측에서 제공한 train셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_txt = ''\n",
    "e = ord('가')\n",
    "\n",
    "for i in range(11172):\n",
    "    ko_txt += chr(e + i)\n",
    "\n",
    "ko_txt += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import string\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/osh/Ocr/customocr-master/customocr-master/hallymocr\")\n",
    "sys.path.append(\"/home/osh/Text Recognition/hallymocr\")\n",
    "# sys.path.insert(0, '/home/osh/Ocr/customocr-master/customocr-master/hallymocr')\n",
    "from hallymocr.train import train\n",
    "from hallymocr.test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n"
     ]
    }
   ],
   "source": [
    "# 1차 학습 하이퍼파라미터 설정\n",
    "opt = {\n",
    "    'exp_name': None,\n",
    "    'train_data': '/home/osh/Ocr/customocr-master/customocr-master/result',\n",
    "    'valid_data': '/home/osh/Ocr/customocr-master/customocr-master/result/valid',\n",
    "    'manualSeed': 1111,\n",
    "    'workers': 4,\n",
    "    'batch_size': 32,\n",
    "    'num_iter': 120000,\n",
    "    'valInterval': 1000,\n",
    "    'saved_model': '',\n",
    "\n",
    "    'FT': False,\n",
    "    'adam': False,\n",
    "    'lr': 1,\n",
    "    'beta1': 0.9,\n",
    "    'rho': 0.95,\n",
    "    'eps': 1e-8,\n",
    "    'grad_clip': 5,\n",
    "    'baiduCTC': False,\n",
    "    'select_data': 'train',\n",
    "    'batch_ratio': '1',\n",
    "    'total_data_usage_ratio': '1',\n",
    "    'batch_max_length': 15,\n",
    "\n",
    "    'imgH': 64,\n",
    "    'imgW': 224,\n",
    "    'rgb': False,\n",
    "    'character': ko_txt,\n",
    "    'sensitive': False,\n",
    "    'PAD': False,\n",
    "    'data_filtering_off': False,\n",
    "    'Transformation': 'TPS',  # None|TPS\n",
    "    'FeatureExtraction': 'ResNet',  # VGG|ResNet|RCNN\n",
    "    'SequenceModeling': 'BiLSTM',  # None|BiLSTM\n",
    "    'Prediction': 'Attn',  # CTC|Attn\n",
    "    'num_fiducial': 20,\n",
    "    'input_channel': 1,\n",
    "    'output_channel': 512,\n",
    "    'hidden_size': 256,\n",
    "}\n",
    "\n",
    "# 모델 추가 세부사항 설정\n",
    "if not opt['exp_name']:\n",
    "    opt['exp_name'] = '{Transformation}-{FeatureExtraction}-{SequenceModeling}-{Prediction}'.format(**opt)\n",
    "    opt['exp_name'] += '-Seed{manualSeed}'.format(**opt)\n",
    "    # print(opt.exp_name)\n",
    "\n",
    "os.makedirs('./saved_models/{exp_name}'.format(**opt), exist_ok=True)\n",
    "\n",
    "\"\"\" Seed and GPU setting \"\"\"\n",
    "random.seed(opt['manualSeed'])\n",
    "np.random.seed(opt['manualSeed'])\n",
    "torch.manual_seed(opt['manualSeed'])\n",
    "torch.cuda.manual_seed(opt['manualSeed'])\n",
    "\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "opt['num_gpu'] = torch.cuda.device_count()\n",
    "\n",
    "if opt['num_gpu'] > 1:\n",
    "    print('------ Use multi-GPU setting ------')\n",
    "    print('if you stuck too long time with multi-GPU setting, try to set --workers 0')\n",
    "    opt['workers'] = opt['workers'] * opt['num_gpu']\n",
    "    opt['batch_size'] = opt['batch_size'] * opt['num_gpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /home/osh/Ocr/customocr-master/customocr-master/result\n",
      "opt.select_data: ['train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /home/osh/Ocr/customocr-master/customocr-master/result\t dataset: train\n",
      "sub-directory:\t/train\t num samples: 75888\n",
      "num total samples of train: 75888 x 1 (total_data_usage_ratio) = 75888\n",
      "num samples of train per batch: 64 x 1.0 (batch_ratio) = 64\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 64 = 64\n",
      "--------------------------------------------------------------------------------\n",
      "<dataset.Batch_Balanced_Dataset object at 0x7fb22c7387c0>\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /home/osh/Ocr/customocr-master/customocr-master/result\n",
      "opt.select_data: ['train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /home/osh/Ocr/customocr-master/customocr-master/result\t dataset: train\n",
      "sub-directory:\t/train\t num samples: 75888\n",
      "num total samples of train: 75888 x 1 (total_data_usage_ratio) = 75888\n",
      "num samples of train per batch: 64 x 1.0 (batch_ratio) = 64\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 64 = 64\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /home/osh/Ocr/customocr-master/customocr-master/result/valid\t dataset: /\n",
      "sub-directory:\t/.\t num samples: 1000\n",
      "--------------------------------------------------------------------------------\n",
      "model input parameters 64 224 20 1 512 256 11175 15 TPS ResNet BiLSTM Attn\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (Transformation): TPS_SpatialTransformerNetwork(\n",
      "      (LocalizationNetwork): LocalizationNetwork(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU(inplace=True)\n",
      "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): ReLU(inplace=True)\n",
      "          (15): AdaptiveAvgPool2d(output_size=1)\n",
      "        )\n",
      "        (localization_fc1): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
      "      )\n",
      "      (GridGenerator): GridGenerator()\n",
      "    )\n",
      "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "      (ConvNet): ResNet(\n",
      "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (modify_GAP): AdaptiveAvgPool2d(output_size=(None, 512))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Attention(\n",
      "      (attention_cell): AttentionCell(\n",
      "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
      "        (rnn): LSTMCell(11431, 256)\n",
      "      )\n",
      "      (generator): Linear(in_features=256, out_features=11175, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable params num :  63821679\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-08\n",
      "    lr: 1\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/120000 [00:10<352:44:22, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/120000] Train loss: 9.34474, Valid loss: 9.26409, Elapsed_time: 4.33333\n",
      "Current_accuracy : 0.000, Current_norm_ED  : 0.00\n",
      "Best_accuracy    : 0.000, Best_norm_ED     : 0.00\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "자네                        | 큕쓨쓨콀콀콀콀콀콀콀콀콀콀콀콀           | 0.0000\tFalse\n",
      "법칙                        | 큕댚댚씜씜씜씜씜씜혝혝혝혝혝혝           | 0.0000\tFalse\n",
      "겁                         | 큕댚댚씜씜씜씜씜씜씜씜씜혝혝혝           | 0.0000\tFalse\n",
      "알                         | 큕댚콀콀콀콀콀콀콀콀콀큕갺큕갺           | 0.0000\tFalse\n",
      "포스터                       | 큕몚쓨씜씜씜씜씜씜씜씜씜씜씜씜           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1000/120000 [06:52<62:09:17,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000/120000] Train loss: 4.50635, Valid loss: 4.10225, Elapsed_time: 407.67607\n",
      "Current_accuracy : 0.000, Current_norm_ED  : 0.07\n",
      "Best_accuracy    : 0.000, Best_norm_ED     : 0.07\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "돌아다니다                     | 아다하다                      | 0.0002\tFalse\n",
      "종                         |                           | 0.0000\tFalse\n",
      "원                         |                           | 0.0000\tFalse\n",
      "과장                        | 그                         | 0.0128\tFalse\n",
      "분량                        | 아다                        | 0.0010\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2000/120000 [14:02<70:53:48,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000/120000] Train loss: 3.85531, Valid loss: 3.84089, Elapsed_time: 837.11533\n",
      "Current_accuracy : 0.100, Current_norm_ED  : 0.09\n",
      "Best_accuracy    : 0.100, Best_norm_ED     : 0.09\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "흥미롭다                      | 지리하다                      | 0.0005\tFalse\n",
      "전                         | 이                         | 0.0140\tFalse\n",
      "밂                         | 이                         | 0.0112\tFalse\n",
      "정확하다                      | 지리하다                      | 0.0007\tFalse\n",
      "금                         | 이                         | 0.0131\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 3000/120000 [21:16<67:51:12,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000/120000] Train loss: 3.63683, Valid loss: 3.54843, Elapsed_time: 1271.01080\n",
      "Current_accuracy : 0.400, Current_norm_ED  : 0.12\n",
      "Best_accuracy    : 0.400, Best_norm_ED     : 0.12\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "공격하다                      | 그정하다                      | 0.0004\tFalse\n",
      "대단하다                      | 지구하다                      | 0.0006\tFalse\n",
      "전문적                       | 이하다                       | 0.0028\tFalse\n",
      "아무개                       | 아구이                       | 0.0001\tFalse\n",
      "쓴맛                        | 부정                        | 0.0003\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4000/120000 [28:33<65:28:59,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000/120000] Train loss: 3.40338, Valid loss: 3.30460, Elapsed_time: 1707.72753\n",
      "Current_accuracy : 0.600, Current_norm_ED  : 0.14\n",
      "Best_accuracy    : 0.600, Best_norm_ED     : 0.14\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "큰절                        | 수장                        | 0.0004\tFalse\n",
      "즐거워하다                     | 그어워하다                     | 0.0002\tFalse\n",
      "대도시                       | 지우다                       | 0.0002\tFalse\n",
      "생물                        | 부장                        | 0.0005\tFalse\n",
      "뉨                         | 분                         | 0.0060\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5000/120000 [35:51<69:58:21,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000/120000] Train loss: 3.15560, Valid loss: 3.07492, Elapsed_time: 2146.07456\n",
      "Current_accuracy : 0.700, Current_norm_ED  : 0.16\n",
      "Best_accuracy    : 0.700, Best_norm_ED     : 0.16\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "아무                        | 가장                        | 0.0083\tFalse\n",
      "리                         | 저                         | 0.0370\tFalse\n",
      "일어나다                      | 정어나다                      | 0.0022\tFalse\n",
      "편히                        | 연히                        | 0.0098\tFalse\n",
      "큰소리                       | 정고적                       | 0.0004\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6000/120000 [43:11<70:12:07,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6000/120000] Train loss: 2.86465, Valid loss: 2.89771, Elapsed_time: 2585.32514\n",
      "Current_accuracy : 1.800, Current_norm_ED  : 0.20\n",
      "Best_accuracy    : 1.800, Best_norm_ED     : 0.20\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "일어나다                      | 뛰어나다                      | 0.0059\tFalse\n",
      "퍽                         | 번                         | 0.0052\tFalse\n",
      "거두다                       | 나우다                       | 0.0372\tFalse\n",
      "돌아다니다                     | 돌아나다                      | 0.0015\tFalse\n",
      "왜                         | 그                         | 0.3993\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7000/120000 [50:31<67:55:22,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7000/120000] Train loss: 2.53360, Valid loss: 2.40237, Elapsed_time: 3025.54374\n",
      "Current_accuracy : 8.800, Current_norm_ED  : 0.30\n",
      "Best_accuracy    : 8.800, Best_norm_ED     : 0.30\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "펼                         | 불                         | 0.0174\tFalse\n",
      "편히                        | 감히                        | 0.0170\tFalse\n",
      "인제                        | 인제                        | 0.0615\tTrue\n",
      "톼                         | 위                         | 0.0071\tFalse\n",
      "판                         | 만                         | 0.0521\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8000/120000 [57:44<62:47:59,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000/120000] Train loss: 2.19884, Valid loss: 2.09554, Elapsed_time: 3459.15831\n",
      "Current_accuracy : 15.700, Current_norm_ED  : 0.38\n",
      "Best_accuracy    : 15.700, Best_norm_ED     : 0.38\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "바라보다                      | 바라보다                      | 0.0967\tTrue\n",
      "어서                        | 어서                        | 0.1484\tTrue\n",
      "자네                        | 사세                        | 0.0440\tFalse\n",
      "숨다                        | 달다                        | 0.0253\tFalse\n",
      "옳                         | 별                         | 0.0162\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9000/120000 [1:04:53<64:31:45,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9000/120000] Train loss: 1.87882, Valid loss: 1.85672, Elapsed_time: 3888.22414\n",
      "Current_accuracy : 20.900, Current_norm_ED  : 0.43\n",
      "Best_accuracy    : 20.900, Best_norm_ED     : 0.43\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "생각나다                      | 생전저지                      | 0.0034\tFalse\n",
      "한                         | 한                         | 0.7108\tTrue\n",
      "갸                         | 가                         | 0.3760\tFalse\n",
      "뎡                         | 명                         | 0.0370\tFalse\n",
      "및                         | 원                         | 0.0255\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10000/120000 [1:12:01<67:21:37,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000/120000] Train loss: 1.62050, Valid loss: 1.50454, Elapsed_time: 4315.81624\n",
      "Current_accuracy : 33.700, Current_norm_ED  : 0.54\n",
      "Best_accuracy    : 33.700, Best_norm_ED     : 0.54\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "찔                         | 월                         | 0.0315\tFalse\n",
      "유교                        | 유교                        | 0.2244\tTrue\n",
      "화제                        | 화제                        | 0.5892\tTrue\n",
      "적합하다                      | 적행하다                      | 0.0414\tFalse\n",
      "뢰                         | 위                         | 0.0813\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11000/120000 [1:19:09<66:23:53,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11000/120000] Train loss: 1.40672, Valid loss: 1.35300, Elapsed_time: 4743.64747\n",
      "Current_accuracy : 39.500, Current_norm_ED  : 0.58\n",
      "Best_accuracy    : 39.500, Best_norm_ED     : 0.58\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "연령                        | 연력                        | 0.2689\tFalse\n",
      "분                         | 분                         | 0.4274\tTrue\n",
      "갈등                        | 잘동                        | 0.0410\tFalse\n",
      "더불다                       | 더불다                       | 0.1738\tTrue\n",
      "월급                        | 원급                        | 0.0296\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 12000/120000 [1:26:17<65:40:46,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12000/120000] Train loss: 1.23101, Valid loss: 1.22772, Elapsed_time: 5171.99439\n",
      "Current_accuracy : 45.400, Current_norm_ED  : 0.62\n",
      "Best_accuracy    : 45.400, Best_norm_ED     : 0.62\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "충돌                        | 복물                        | 0.0406\tFalse\n",
      "숍                         | 꼭                         | 0.0031\tFalse\n",
      "집단                        | 집단                        | 0.3423\tTrue\n",
      "체온                        | 체우                        | 0.5388\tFalse\n",
      "틸                         | 월                         | 0.0221\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 13000/120000 [1:33:25<66:20:37,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13000/120000] Train loss: 1.10147, Valid loss: 1.03250, Elapsed_time: 5599.19059\n",
      "Current_accuracy : 52.000, Current_norm_ED  : 0.65\n",
      "Best_accuracy    : 52.000, Best_norm_ED     : 0.65\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "늦다                        | 붓다                        | 0.0625\tFalse\n",
      "단위                        | 단위                        | 0.7182\tTrue\n",
      "제작하다                      | 계작하다                      | 0.1541\tFalse\n",
      "기억나다                      | 기억나다                      | 0.2644\tTrue\n",
      "자기                        | 자기                        | 0.9773\tTrue\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 14000/120000 [1:40:33<67:03:31,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14000/120000] Train loss: 0.98997, Valid loss: 0.98442, Elapsed_time: 6027.37309\n",
      "Current_accuracy : 55.500, Current_norm_ED  : 0.68\n",
      "Best_accuracy    : 55.500, Best_norm_ED     : 0.68\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "그리로                       | 그리로                       | 0.7085\tTrue\n",
      "새끼                        | 새끼                        | 0.6153\tTrue\n",
      "보도                        | 보도                        | 0.9444\tTrue\n",
      "켜다                        | 켜다                        | 0.0556\tTrue\n",
      "와                         | 와                         | 0.3768\tTrue\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 14017/120000 [1:40:41<12:41:18,  2.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/osh/Ocr/customocr-master/customocr-master/ocr copy 2.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3131352e3232392e3438222c2275736572223a226f7368222c22706f7274223a313231317d/home/osh/Ocr/customocr-master/customocr-master/ocr%20copy%202.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3131352e3232392e3438222c2275736572223a226f7368222c22706f7274223a313231317d/home/osh/Ocr/customocr-master/customocr-master/ocr%20copy%202.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train(opt)\n",
      "File \u001b[0;32m~/Ocr/customocr-master/customocr-master/hallymocr/train.py:278\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    276\u001b[0m cost\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    277\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), opt[\u001b[39m'\u001b[39m\u001b[39mgrad_clip\u001b[39m\u001b[39m'\u001b[39m])  \u001b[39m# gradient clipping with 5 (Default)\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    280\u001b[0m loss_avg\u001b[39m.\u001b[39madd(cost)\n\u001b[1;32m    282\u001b[0m \u001b[39m# validation part\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/adadelta.py:105\u001b[0m, in \u001b[0;36mAdadelta.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m         acc_deltas\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39macc_delta\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    103\u001b[0m         state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 105\u001b[0m     F\u001b[39m.\u001b[39;49madadelta(params_with_grad,\n\u001b[1;32m    106\u001b[0m                grads,\n\u001b[1;32m    107\u001b[0m                square_avgs,\n\u001b[1;32m    108\u001b[0m                acc_deltas,\n\u001b[1;32m    109\u001b[0m                lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    110\u001b[0m                rho\u001b[39m=\u001b[39;49mrho,\n\u001b[1;32m    111\u001b[0m                eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    112\u001b[0m                weight_decay\u001b[39m=\u001b[39;49mweight_decay)\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/optim/_functional.py:204\u001b[0m, in \u001b[0;36madadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, lr, rho, eps, weight_decay)\u001b[0m\n\u001b[1;32m    202\u001b[0m std \u001b[39m=\u001b[39m square_avg\u001b[39m.\u001b[39madd(eps)\u001b[39m.\u001b[39msqrt_()\n\u001b[1;32m    203\u001b[0m delta \u001b[39m=\u001b[39m acc_delta\u001b[39m.\u001b[39madd(eps)\u001b[39m.\u001b[39msqrt_()\u001b[39m.\u001b[39mdiv_(std)\u001b[39m.\u001b[39mmul_(grad)\n\u001b[0;32m--> 204\u001b[0m param\u001b[39m.\u001b[39;49madd_(delta, alpha\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mlr)\n\u001b[1;32m    205\u001b[0m acc_delta\u001b[39m.\u001b[39mmul_(rho)\u001b[39m.\u001b[39maddcmul_(delta, delta, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m rho)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dacon 데이터로 2차 학습\n",
    "외부데이터로 학습된 1차 학습에서 가장 좋은 정확도를 보인 모델을 불러와 </br>\n",
    "오타, 띄어쓰기, 이상값 등을 수작업으로 정제한 Dacon Train파일을 학습데이터로 사용하여 추가학습을 진행합니다. </br>\n",
    "이때 train셋은 Dacon Train셋의 -1000번째 까지이며 validation은 Dacon Train셋의 끝에서 1000번째 까지의 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "opt['exp_name'] = '{Transformation}-{FeatureExtraction}-{SequenceModeling}-{Prediction}-Seed{manualSeed}'.format(**opt)\n",
    "opt['saved_model'] = 'saved_models/{Transformation}-{FeatureExtraction}-{SequenceModeling}-{Prediction}-Seed{manualSeed}/best_accuracy.pth'.format(**opt)\n",
    "opt['num_iter'] = 1000\n",
    "opt['lr'] = 0.001\n",
    "opt['select_data'] = 'train'\n",
    "opt['valid_data'] = './result/valid'\n",
    "opt['batch_ratio'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /home/osh/Ocr/customocr-master/customocr-master/result\n",
      "opt.select_data: ['train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /home/osh/Ocr/customocr-master/customocr-master/result\t dataset: train\n",
      "sub-directory:\t/train\t num samples: 75888\n",
      "num total samples of train: 75888 x 1 (total_data_usage_ratio) = 75888\n",
      "num samples of train per batch: 64 x 1.0 (batch_ratio) = 64\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 64 = 64\n",
      "--------------------------------------------------------------------------------\n",
      "<dataset.Batch_Balanced_Dataset object at 0x7f881b1b4640>\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /home/osh/Ocr/customocr-master/customocr-master/result\n",
      "opt.select_data: ['train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /home/osh/Ocr/customocr-master/customocr-master/result\t dataset: train\n",
      "sub-directory:\t/train\t num samples: 75888\n",
      "num total samples of train: 75888 x 1 (total_data_usage_ratio) = 75888\n",
      "num samples of train per batch: 64 x 1.0 (batch_ratio) = 64\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 64 = 64\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    ./result/valid\t dataset: /\n",
      "sub-directory:\t/.\t num samples: 1000\n",
      "--------------------------------------------------------------------------------\n",
      "model input parameters 64 224 20 1 512 256 11175 15 TPS ResNet BiLSTM Attn\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "loading pretrained model from saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (Transformation): TPS_SpatialTransformerNetwork(\n",
      "      (LocalizationNetwork): LocalizationNetwork(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU(inplace=True)\n",
      "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): ReLU(inplace=True)\n",
      "          (15): AdaptiveAvgPool2d(output_size=1)\n",
      "        )\n",
      "        (localization_fc1): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
      "      )\n",
      "      (GridGenerator): GridGenerator()\n",
      "    )\n",
      "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "      (ConvNet): ResNet(\n",
      "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (modify_GAP): AdaptiveAvgPool2d(output_size=(None, 512))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Attention(\n",
      "      (attention_cell): AttentionCell(\n",
      "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
      "        (rnn): LSTMCell(11431, 256)\n",
      "      )\n",
      "      (generator): Linear(in_features=256, out_features=11175, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable params num :  63821679\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:06<1:43:51,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] Train loss: 0.02943, Valid loss: 0.04565, Elapsed_time: 0.43189\n",
      "Current_accuracy : 97.900, Current_norm_ED  : 0.99\n",
      "Best_accuracy    : 97.900, Best_norm_ED     : 0.99\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "계산하다                      | 계산하다                      | 0.9990\tTrue\n",
      "눈                         | 눈                         | 0.9991\tTrue\n",
      "내다보다                      | 내다보다                      | 0.9997\tTrue\n",
      "그래                        | 그래                        | 0.9998\tTrue\n",
      "믓                         | 믓                         | 0.9730\tTrue\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 999/1000 [07:00<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000/1000] Train loss: 0.00447, Valid loss: 0.05232, Elapsed_time: 416.97926\n",
      "Current_accuracy : 97.800, Current_norm_ED  : 0.99\n",
      "Best_accuracy    : 97.900, Best_norm_ED     : 0.99\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "켱                         | 켱                         | 0.9868\tTrue\n",
      "알                         | 알                         | 0.9975\tTrue\n",
      "고전                        | 고전                        | 0.9998\tTrue\n",
      "낯설다                       | 낯설다                       | 0.9964\tTrue\n",
      "아뇨                        | 아뇨                        | 0.9986\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "end the training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 최종 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # 저장된 모델 load\n",
    "# opt['saved_model'] = 'saved_models/{Transformation}-{FeatureExtraction}-{SequenceModeling}-{Prediction}-Seed{manualSeed}/best_accuracy.pth'.format(**opt)\n",
    "# opt['test_data'] = '/home/osh/Ocr/customocr-master/customocr-master/result/test'\n",
    "# # opt['test_data'] = './test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 load\n",
    "opt['saved_model'] = 'saved_models/{Transformation}-{FeatureExtraction}-{SequenceModeling}-{Prediction}-Seed{manualSeed}/best_accuracy.pth'.format(**opt)\n",
    "opt['test_data'] = \"/home/osh/Text Recognition/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input parameters 64 224 20 1 512 256 11175 15 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth\n"
     ]
    }
   ],
   "source": [
    "result = test(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# result_csv_path = '/home/osh/Text Recognition/sample_submission.csv'\n",
    "result_csv_path = '/home/osh/Text Recognition/sample_submission.csv'\n",
    "result_csv = pd.read_csv(result_csv_path)\n",
    "\n",
    "result_csv['label'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "time = datetime.now().strftime('%m%d_%H%M')\n",
    "csv_name = f'{time}.csv'\n",
    "result_csv.to_csv(csv_name, index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>날말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>상황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>받아들이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>바구니</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>살</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74116</th>\n",
       "      <td>TEST_74116</td>\n",
       "      <td>캐나다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74117</th>\n",
       "      <td>TEST_74117</td>\n",
       "      <td>사무</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74118</th>\n",
       "      <td>TEST_74118</td>\n",
       "      <td>친절하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74119</th>\n",
       "      <td>TEST_74119</td>\n",
       "      <td>쪽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74120</th>\n",
       "      <td>TEST_74120</td>\n",
       "      <td>부정하다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  label\n",
       "0      TEST_00000     날말\n",
       "1      TEST_00001     상황\n",
       "2      TEST_00002  받아들이다\n",
       "3      TEST_00003    바구니\n",
       "4      TEST_00004      살\n",
       "...           ...    ...\n",
       "74116  TEST_74116    캐나다\n",
       "74117  TEST_74117     사무\n",
       "74118  TEST_74118   친절하다\n",
       "74119  TEST_74119      쪽\n",
       "74120  TEST_74120   부정하다\n",
       "\n",
       "[74121 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "20795f3e8399290024a564bf0464b4685d8636e453f4f4f3370f406b581552c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
