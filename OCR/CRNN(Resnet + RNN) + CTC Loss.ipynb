{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OH\\Anaconda3\\envs\\pytorch1\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "# from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2724050-75a4-4304-824c-23873f5908fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_HEIGHT_SIZE':64,\n",
    "    'IMG_WIDTH_SIZE':224, # 224\n",
    "    'EPOCHS':200,\n",
    "    'LEARNING_RATE':2e-3, # 0.001 = 1e-3, 0.01 = 1e-2, 0.002\n",
    "    'BATCH_SIZE':64,\n",
    "    'NUM_WORKERS':0, # 본인의 GPU, CPU 환경에 맞게 설정\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Load & Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./train.csv')\n",
    "df = pd.read_csv('C:/Users/OH/python/Dacon/Text Recognition/train.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf1e9b48-74b0-4467-bd23-5e67b4ad0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 학습데이터 중 1글자 샘플들의 단어사전이 학습/테스트 데이터의 모든 글자를 담고 있으므로 학습 데이터로 우선 배치\n",
    "df['len'] = df['label'].str.len()\n",
    "train_v1 = df[df['len']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ef1d10-8f7d-4807-aec4-728bf08a2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제공된 학습데이터 중 2글자 이상의 샘플들에 대해서 단어길이를 고려하여 Train (80%) / Validation (20%) 분할\n",
    "df = df[df['len']>1]\n",
    "train_v2, val, _, _ = train_test_split(df, df['len'], test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53142c6-4d17-44a1-a0c1-c23ee7f83f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66251 10637\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터로 우선 배치한 1글자 샘플들과 분할된 2글자 이상의 학습 샘플을 concat하여 최종 학습 데이터로 사용\n",
    "train = pd.concat([train_v1, train_v2])\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43b671-f8a5-403a-b2aa-7f779f6fd85a",
   "metadata": {},
   "source": [
    "## Get Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a384ae9-fc56-4660-96c2-0d424f64ea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2349\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터로부터 단어 사전(Vocabulary) 구축\n",
    "train_gt = [gt for gt in train['label']]\n",
    "train_gt = \"\".join(train_gt)\n",
    "letters = sorted(list(set(list(train_gt))))\n",
    "print(len(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be0b36a1-bc45-4e2c-9f0a-e8f3e845299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350\n"
     ]
    }
   ],
   "source": [
    "vocabulary = [\"-\"] + letters\n",
    "print(len(vocabulary))\n",
    "idx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\n",
    "char2idx = {v:k for k,v in idx2char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_path_list[index]).convert('RGB')\n",
    "        \n",
    "        if self.train_mode:\n",
    "            image = self.train_transform(image)\n",
    "        else:\n",
    "            image = self.test_transform(image)\n",
    "            \n",
    "        if self.label_list is not None:\n",
    "            text = self.label_list[index]\n",
    "            return image, text\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    # Image Augmentation\n",
    "    def train_transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.Resize((CFG['IMG_HEIGHT_SIZE'],CFG['IMG_WIDTH_SIZE'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)\n",
    "    \n",
    "    def test_transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.Resize((CFG['IMG_HEIGHT_SIZE'],CFG['IMG_WIDTH_SIZE'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            # 데이터 포인트가 동일한 정도의 스케일(중요도)로 반영\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'])\n",
    "\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eccac93-a67b-4b45-908a-2283131fd5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 224]) ('신비', '그나마', '씻기다', '쉴', '일반', '셋', '수입되다', '세', '달리다', '뜁', '선원', '추가', '대량', '예매하다', '콩', '쯩', '못', '사모님', '뱀', '호주머니', '젤', '벌', '불', '베개', '수도권', '회복되다', '날씨', '유산', '견해', '체조', '얘', '튀김', '삼계탕', '어려움', '세', '발자국', '터', '함께', '스타', '샛', '참여하다', '븐', '학생증', '신인', '신청', '양복', '추진하다', '집중하다', '구분되다', '기타', '지구', '꽐', '명예', '대륙', '천장', '신', '칡', '창조', '걋', '나무', '향', '여행사', '강', '흄')\n"
     ]
    }
   ],
   "source": [
    "image_batch, text_batch = iter(train_loader).next()\n",
    "print(image_batch.size(), text_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959d9dc0-0f23-47d7-8f97-cfc01f0fc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionModel(nn.Module):\n",
    "    def __init__(self, num_chars=len(char2idx), rnn_hidden_size=256): # 256\n",
    "        super(RecognitionModel, self).__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        \n",
    "        # CNN Backbone = 사전학습된 resnet18 활용\n",
    "        # https://arxiv.org/abs/1512.03385\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        # CNN Feature Extract\n",
    "        resnet_modules = list(resnet.children())[:-3]\n",
    "        self.feature_extract = nn.Sequential(\n",
    "            *resnet_modules,\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 6), stride=1, padding=1), # 256 256 kernel_size = (3, 6), 1024 1024 kernel_size = (4, 14), \n",
    "            nn.BatchNorm2d(256), # 256, 2048, 2 \n",
    "            # 학습 과정에서 각 배치 단위 별로 데이터가 다양한 분포를 가지더라도 각 배치별로 평균과 분산을 이용해 정규화하는것\n",
    "            nn.ReLU(inplace=True)\n",
    "            # Sigmoid와 tanh가 갖는 Gradient Vanishing 문제를 해결하기 위한 함수 0보다 작을 때 0, 0보다 크면 그 값\n",
    "        )\n",
    "\n",
    "        # input_feature = 1024, output_feature = 256\n",
    "        self.linear1 = nn.Linear(1024, rnn_hidden_size) # 1024, 6144, 6\n",
    "        # 선형 회귀 모델, 입력 1024, 출력 256\n",
    "        \n",
    "        # RNN\n",
    "        # rnn 입력 : [sequence, batch_size, input_size]\n",
    "        self.rnn = nn.RNN(input_size=rnn_hidden_size, \n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "                            \n",
    "        # RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징\n",
    "        # input_feature = 256*2, output_feature = num_chars=len(char2idx) = 2350                            \n",
    "        self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n",
    "        # 선형 회귀 모델, 입력 512, num_chars = 2350\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        x = self.feature_extract(x) # [batch_size, channels, height, width]\n",
    "        # 특징 추출\n",
    "        x = x.permute(0, 3, 1, 2) # [batch_size, width, channels, height]\n",
    "        # 순서 바꾸기, tensor의 형태를 바꿈\n",
    "         \n",
    "        batch_size = x.size(0) # batch_size\n",
    "        T = x.size(1)\n",
    "        x = x.view(batch_size, T, -1) # [batch_size, T==width, num_features==channels*height]\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        # RNN\n",
    "        x, hidden = self.rnn(x)\n",
    "        \n",
    "        output = self.linear2(x)\n",
    "        output = output.permute(1, 0, 2) # [T==10, batch_size, num_classes==num_features]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RecognitionModel(nn.Module):\n",
    "#     def __init__(self, num_chars=len(char2idx), rnn_hidden_size=256):\n",
    "#         super(RecognitionModel, self).__init__()\n",
    "#         self.num_chars = num_chars\n",
    "#         self.rnn_hidden_size = rnn_hidden_size\n",
    "        \n",
    "#         # CNN Backbone = 사전학습된 resnet18 활용\n",
    "#         # https://arxiv.org/abs/1512.03385\n",
    "#         resnet = resnet50(pretrained=True)\n",
    "#         # CNN Feature Extract\n",
    "#         resnet_modules = list(resnet.children())[:-3]\n",
    "#         self.feature_extract = nn.Sequential(\n",
    "#             *resnet_modules,\n",
    "#             nn.Conv2d(256, 256, kernel_size=(3,6), stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#         self.linear1 = nn.Linear(1024, rnn_hidden_size)\n",
    "        \n",
    "#         # RNN\n",
    "#         self.rnn = nn.RNN(input_size=rnn_hidden_size, \n",
    "#                             hidden_size=rnn_hidden_size,\n",
    "#                             bidirectional=True, \n",
    "#                             batch_first=True)\n",
    "#         self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # CNN\n",
    "#         x = self.feature_extract(x) # [batch_size, channels, height, width]\n",
    "#         # print(\"X1\")\n",
    "#         x = x.permute(0, 3, 1, 2) # [batch_size, width, channels, height]\n",
    "#         # print(\"X2\")\n",
    "#         batch_size = x.size(0)\n",
    "#         T = x.size(1)\n",
    "#         x = x.view(batch_size, T, -1) # [batch_size, T==width, num_features==channels*height]\n",
    "#         x = self.linear1(x)\n",
    "#         # print(\"X3\")\n",
    "        \n",
    "#         # RNN\n",
    "#         x, hidden = self.rnn(x)\n",
    "#         # print(\"X4\")\n",
    "        \n",
    "#         output = self.linear2(x)\n",
    "#         # print(\"X5\")\n",
    "#         output = output.permute(1, 0, 2) # [T==10, batch_size, num_classes==num_features]\n",
    "        \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f5723-1137-4b6d-be4a-47b1c99e2744",
   "metadata": {},
   "source": [
    "## Define CTC Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32a34330-d5cd-4703-8930-45bd238e04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss(blank=0) # idx 0 : '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda15898-58b3-4431-8aa2-09cc2ea1c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_batch(text_batch):\n",
    "    text_batch_targets_lens = [len(text) for text in text_batch]\n",
    "    text_batch_targets_lens = torch.IntTensor(text_batch_targets_lens)\n",
    "    \n",
    "    text_batch_concat = \"\".join(text_batch)\n",
    "    text_batch_targets = [char2idx[c] for c in text_batch_concat]\n",
    "    text_batch_targets = torch.IntTensor(text_batch_targets)\n",
    "    \n",
    "    return text_batch_targets, text_batch_targets_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2bddfe3-30b0-42a2-8954-a8a19457be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(text_batch, text_batch_logits):\n",
    "    \"\"\"\n",
    "    text_batch: list of strings of length equal to batch size\n",
    "    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n",
    "    \"\"\"\n",
    "    text_batch_logps = F.log_softmax(text_batch_logits, 2) # [T, batch_size, num_classes]  \n",
    "    text_batch_logps_lens = torch.full(size=(text_batch_logps.size(1),), \n",
    "                                       fill_value=text_batch_logps.size(0), \n",
    "                                       dtype=torch.int32).to(device) # [batch_size] \n",
    "\n",
    "    text_batch_targets, text_batch_targets_lens = encode_text_batch(text_batch)\n",
    "    loss = criterion(text_batch_logps, text_batch_targets, text_batch_logps_lens, text_batch_targets_lens)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    best_model = None\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for image_batch, text_batch in tqdm(iter(train_loader)):\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text_batch_logits = model(image_batch)\n",
    "            loss = compute_loss(text_batch, text_batch_logits)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        _train_loss = np.mean(train_loss)\n",
    "        \n",
    "        _val_loss = validation(model, val_loader, device)\n",
    "        print(f'Epoch : [{epoch}] Train CTC Loss : [{_train_loss:.5f}] Val CTC Loss : [{_val_loss:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_loss)\n",
    "        \n",
    "        if best_loss > _val_loss:\n",
    "            best_loss = _val_loss\n",
    "            best_model = model\n",
    "            torch.save(model.state_dict(), 'C:/Users/OH/Desktop/Study/2022-02-01/Modeling/Text Recognition/open/best_model.pth')\n",
    "            print('Model Saved.')\n",
    "            cnt = 0\n",
    "                \n",
    "        # 학습 실패 -> 쌓는다 -> 카운트\n",
    "        if best_loss <= _val_loss:\n",
    "            cnt = cnt + 1\n",
    "            print('cnt : ' , cnt)\n",
    "            if cnt > 5:\n",
    "                break\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb26e02-35de-418b-8948-7447f5822cfe",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18efe906-aeb7-45a6-8db5-aed806fd7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for image_batch, text_batch in tqdm(iter(val_loader)):\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            text_batch_logits = model(image_batch)\n",
    "            loss = compute_loss(text_batch, text_batch_logits)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    \n",
    "    _val_loss = np.mean(val_loss)\n",
    "    return _val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:25<00:00, 12.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train CTC Loss : [5.84649] Val CTC Loss : [3.54457]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:24<00:00, 12.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train CTC Loss : [2.87456] Val CTC Loss : [1.14398]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:23<00:00, 12.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:11<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train CTC Loss : [1.41788] Val CTC Loss : [0.69814]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train CTC Loss : [0.88858] Val CTC Loss : [0.46828]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train CTC Loss : [0.65114] Val CTC Loss : [0.42736]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train CTC Loss : [0.53973] Val CTC Loss : [0.40644]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train CTC Loss : [0.48325] Val CTC Loss : [0.42032]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train CTC Loss : [0.43904] Val CTC Loss : [0.43973]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train CTC Loss : [0.39834] Val CTC Loss : [0.39429]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train CTC Loss : [0.40090] Val CTC Loss : [0.44358]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [11] Train CTC Loss : [0.41295] Val CTC Loss : [0.36676]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [12] Train CTC Loss : [0.35991] Val CTC Loss : [0.41380]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [13] Train CTC Loss : [0.38710] Val CTC Loss : [0.40053]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [14] Train CTC Loss : [0.33922] Val CTC Loss : [0.44496]\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-03.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [15] Train CTC Loss : [0.10327] Val CTC Loss : [0.18193]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [16] Train CTC Loss : [0.05340] Val CTC Loss : [0.21581]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [17] Train CTC Loss : [0.06798] Val CTC Loss : [0.22873]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [18] Train CTC Loss : [0.08726] Val CTC Loss : [0.19316]\n",
      "Epoch 00018: reducing learning rate of group 0 to 5.0000e-04.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:22<00:00, 12.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [19] Train CTC Loss : [0.02657] Val CTC Loss : [0.13935]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:23<00:00, 12.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:10<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [20] Train CTC Loss : [0.00968] Val CTC Loss : [0.14227]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:31<00:00, 11.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:10<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [21] Train CTC Loss : [0.01238] Val CTC Loss : [0.15018]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:30<00:00, 11.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [22] Train CTC Loss : [0.01601] Val CTC Loss : [0.16157]\n",
      "Epoch 00022: reducing learning rate of group 0 to 2.5000e-04.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:25<00:00, 12.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [23] Train CTC Loss : [0.00877] Val CTC Loss : [0.12916]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [24] Train CTC Loss : [0.00276] Val CTC Loss : [0.12242]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:30<00:00, 11.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [25] Train CTC Loss : [0.00157] Val CTC Loss : [0.12009]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [26] Train CTC Loss : [0.00250] Val CTC Loss : [0.13406]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 11.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [27] Train CTC Loss : [0.00505] Val CTC Loss : [0.12468]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:29<00:00, 11.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [28] Train CTC Loss : [0.00222] Val CTC Loss : [0.12505]\n",
      "Epoch 00028: reducing learning rate of group 0 to 1.2500e-04.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [29] Train CTC Loss : [0.00132] Val CTC Loss : [0.12207]\n",
      "cnt :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [30] Train CTC Loss : [0.00082] Val CTC Loss : [0.11760]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:24<00:00, 12.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [31] Train CTC Loss : [0.00057] Val CTC Loss : [0.11583]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:25<00:00, 12.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [32] Train CTC Loss : [0.00069] Val CTC Loss : [0.11604]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [33] Train CTC Loss : [0.00076] Val CTC Loss : [0.11856]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:28<00:00, 11.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [34] Train CTC Loss : [0.00096] Val CTC Loss : [0.11756]\n",
      "Epoch 00034: reducing learning rate of group 0 to 6.2500e-05.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:11<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [35] Train CTC Loss : [0.00042] Val CTC Loss : [0.11848]\n",
      "cnt :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:28<00:00, 11.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:13<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [36] Train CTC Loss : [0.00032] Val CTC Loss : [0.11342]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:12<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [37] Train CTC Loss : [0.00024] Val CTC Loss : [0.11680]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:11<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [38] Train CTC Loss : [0.00031] Val CTC Loss : [0.11090]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:20<00:00, 12.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [39] Train CTC Loss : [0.00020] Val CTC Loss : [0.11051]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:21<00:00, 12.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [40] Train CTC Loss : [0.00025] Val CTC Loss : [0.11070]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:23<00:00, 12.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [41] Train CTC Loss : [0.00018] Val CTC Loss : [0.10915]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [42] Train CTC Loss : [0.00013] Val CTC Loss : [0.10949]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:25<00:00, 12.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:12<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [43] Train CTC Loss : [0.00013] Val CTC Loss : [0.10998]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:10<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [44] Train CTC Loss : [0.00010] Val CTC Loss : [0.11116]\n",
      "Epoch 00044: reducing learning rate of group 0 to 3.1250e-05.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [45] Train CTC Loss : [0.00009] Val CTC Loss : [0.10801]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [46] Train CTC Loss : [0.00009] Val CTC Loss : [0.11279]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:28<00:00, 11.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [47] Train CTC Loss : [0.00009] Val CTC Loss : [0.10679]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:27<00:00, 11.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [48] Train CTC Loss : [0.00007] Val CTC Loss : [0.10483]\n",
      "Model Saved.\n",
      "cnt :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 11.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [49] Train CTC Loss : [0.00011] Val CTC Loss : [0.10868]\n",
      "cnt :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:24<00:00, 12.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [50] Train CTC Loss : [0.00008] Val CTC Loss : [0.10846]\n",
      "cnt :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:28<00:00, 11.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [51] Train CTC Loss : [0.00006] Val CTC Loss : [0.11260]\n",
      "Epoch 00051: reducing learning rate of group 0 to 1.5625e-05.\n",
      "cnt :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:29<00:00, 11.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:08<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [52] Train CTC Loss : [0.00006] Val CTC Loss : [0.10843]\n",
      "cnt :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1036/1036 [01:26<00:00, 12.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 167/167 [00:09<00:00, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [53] Train CTC Loss : [0.00006] Val CTC Loss : [0.10797]\n",
      "cnt :  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RecognitionModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "# from torchsummary import summary\n",
    "# summary(resnet50(pretrained=True).to(device), input_size = (3,64,224), device = \"cuda\")\n",
    "# summary(model.to(device), input_size = (3,64,224), device = \"cuda\")\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b807d-ac45-4183-b92d-2b40f154e66c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23e20fdc-ce3e-49c6-899d-317dde3316c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('./test.csv')\n",
    "test = pd.read_csv('C:/Users/OH/python/Dacon/Text Recognition/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c53fee0-f56f-4491-8a00-af7a18228045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path_t = 'C:/Users/OH/Desktop/Study/2022-02-01/Modeling/Text Recognition/open/test'\n",
    "# img_path_t = 'C:/Users/OH/python/Dacon/Text Recognition/open/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5705b13-5246-4519-b11d-75102322c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bd93adb-adfc-4376-ad73-ed8fc156599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(text_batch_logits):\n",
    "    text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n",
    "    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "\n",
    "    text_batch_tokens_new = []\n",
    "    for text_tokens in text_batch_tokens:\n",
    "        text = [idx2char[idx] for idx in text_tokens]\n",
    "        text = \"\".join(text)\n",
    "        text_batch_tokens_new.append(text)\n",
    "\n",
    "    return text_batch_tokens_new\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for image_batch in tqdm(iter(test_loader)):\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            text_batch_logits = model(image_batch)\n",
    "            \n",
    "            text_batch_pred = decode_predictions(text_batch_logits.cpu())\n",
    "            \n",
    "            preds.extend(text_batch_pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57711ef8-048b-481d-8c98-759a9c81f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1159/1159 [01:58<00:00,  9.81it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3904ed-61af-4db6-896c-2bcd21709b9f",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87e53da9-eb17-4e9a-a5d7-857143128961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 별 추론결과를 독립적으로 후처리\n",
    "def remove_duplicates(text):\n",
    "    if len(text) > 1:\n",
    "        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n",
    "    elif len(text) == 1:\n",
    "        letters = [text[0]]\n",
    "    else:\n",
    "        return \"\"\n",
    "    return \"\".join(letters)\n",
    "\n",
    "def correct_prediction(word):\n",
    "    parts = word.split(\"-\")\n",
    "    parts = [remove_duplicates(part) for part in parts]\n",
    "    corrected_word = \"\".join(parts)\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55c6f77c-afe4-4a75-848f-757e498f2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "submit = pd.read_csv('C:/Users/OH/python/Dacon/Text Recognition/sample_submission.csv')\n",
    "submit['label'] = predictions\n",
    "submit['label'] = submit['label'].apply(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d5f4863-49d8-4e90-92c8-b500e0b275d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./submission6.csv', index=False, encoding = 'cp949')\n",
    "submit.to_csv('./submission3.csv', index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf4ba8-78ab-4dc3-b324-849c88832334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
